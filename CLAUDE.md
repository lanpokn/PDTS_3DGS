# Claude Memory for 3DGS + Active Sampling Project

## ğŸ¯ ULTIMATE PROJECT GOAL
**Replace Direct Loss Calculation with Neural Network Prediction**
- **Problem**: Computing loss for all views via 3DGS forward pass is too time-consuming
- **Solution**: Train a neural network that takes views as input and predicts loss as output
- **Method**: Adapt PDTS's risk learner approach to 3DGS view selection
- **Architecture**: Network(view) â†’ predicted_loss, then use PDTS sampling strategies

## Project Overview
This is a dual project combining:
1. **3DGS (3D Gaussian Splatting)** - Famous real-time radiance field rendering implementation  
2. **PDTS (Posterior and Diversity Synergized Task Sampling)** - Novel robust active task sampling research project
3. **Integration Goal**: Use PDTS's risk prediction network to accelerate 3DGS view selection

## 3DGS Main Project - MODIFIED WITH LOSS-BASED VIEW SELECTION
- **Core Implementation**: Standard 3D Gaussian Splatting for real-time rendering
- **Key Files**: train.py (MODIFIED), render.py, scene/, utils/, gaussian_renderer/
- **Status**: Enhanced with intelligent view selection algorithm

### CURRENT IMPLEMENTATION: Direct Loss-Based View Selection (FIXED)
**Implementation Details:**
- **Flag**: `--loss_judge` enables the current algorithm
- **Parameter**: `--num_selected_views` (default: 16) - both number of views to select AND training interval
- **Algorithm**: Every N iterations, randomly select 32 candidates, evaluate their loss, select top N with highest loss
- **Current Usage**: `--num_selected_views 4` (32é€‰4ç­–ç•¥)
- **Command**: `python train.py -s <dataset> -m <output> --iterations 2000 --loss_judge --num_selected_views 4`
- **Key Fix**: Changed from "evaluate ALL views" to "evaluate 32 random candidates" to maintain randomness
- **Limitation**: Still requires 3DGS forward pass for candidates â†’ SLOW but more reasonable

### âœ… IMPLEMENTED: PDTS Neural Network Integration 
**Code Location**: `pdts_integration.py` + modifications in `train.py`

#### **1. Core Neural Network Components** (ç›´æ¥å¤åˆ¶è‡ªPDTSæºç ):
**æ¥æº**: `PDTS/sinusoid/Model/risklearner.py` + `PDTS/sinusoid/Model/backbone_risklearner.py`
- **Encoder**: Maps (camera_features, loss) â†’ representation r_i
- **MuSigmaEncoder**: Aggregates representations â†’ Î¼,Ïƒ for latent variable z  
- **Decoder**: Maps (camera_features, z) â†’ predicted loss
- **RiskLearner**: Neural Processæ¶æ„ (x_dim=13, y_dim=1, r_dim=10, z_dim=10, h_dim=10) - å·²æ›´æ–°ç»´åº¦

#### **2. Training Logic** (å¤åˆ¶è‡ªPDTS trainer):
**æ¥æº**: `PDTS/sinusoid/Model/trainer_risklearner.py`
- **Losså‡½æ•°**: MSE reconstruction loss + KL divergence regularization  
- **Prioræ›´æ–°**: ç”¨å˜åˆ†åéªŒæ›´æ–°å…ˆéªŒåˆ†å¸ƒ (Line 164-166)
- **è®­ç»ƒé¢‘ç‡**: æ¯num_selected_viewsè½®è®­ç»ƒä¸€æ¬¡ (æ¨¡ä»¿PDTSçš„æ¯epochè®­ç»ƒ)

#### **3. View Selection Strategy** (IMPROVED å·²ä¿®å¤):
**æ¥æº**: `PDTS/sinusoid/trainer_maml.py` Line 178-199 ("diverse"åˆ†æ”¯)
- **Posterior Sampling**: çœŸæ­£çš„éšæœºé‡‡æ · (è¿”å›å•ä¸ªstochastic predictionè€Œéå‡å€¼)
- **Diversity Regularization**: ä¿®å¤çš„MSDç®—æ³•ï¼Œæ­£ç¡®çš„å½’ä¸€åŒ–å’Œæƒé‡å¹³è¡¡
- **Bootstrap Phase**: å‰200è½®éšæœºé‡‡æ ·æ”¶é›†åˆå§‹æ•°æ®

**Critical Fixes Applied:**
- âœ… **Fixed Posterior Sampling**: `predict_for_sampling`ç°åœ¨è¿”å›å•ä¸ªéšæœºæ ·æœ¬è€Œéç¡®å®šæ€§å‡å€¼
- âœ… **Fixed Diversity Scoring**: å®ç°Min-Maxå½’ä¸€åŒ–ï¼Œç¡®ä¿acquisition_scoreå’Œdiversity_scoreåœ¨ç›¸åŒå°ºåº¦[0,1]
- âœ… **Added Trade-off Parameter**: `lambda_diversity`å‚æ•°å®ç°çœŸæ­£çš„å¹³è¡¡: `(1-Î»)*acquisition + Î»*diversity`

#### **4. Camera Feature Extraction** (IMPROVED å·²ä¿®å¤):
**è®¾è®¡åŸç†**: å°†3DGSç›¸æœºå‚æ•°è½¬æ¢ä¸ºç½‘ç»œè¾“å…¥ç‰¹å¾
```python
# 13ç»´ç‰¹å¾å‘é‡ (å·²æ”¹è¿›):
- camera_center (3D): ä¸–ç•Œåæ ‡ä¸­çš„ç›¸æœºä½ç½®
- rotation_6d (6D): 6Dæ—‹è½¬è¡¨ç¤º (æ›¿ä»£æ¬§æ‹‰è§’ï¼Œé¿å…ä¸‡å‘é”)
- fov (2D): FoVx, FoVyè§†åœºè§’
- resolution (2D): å›¾åƒå®½é«˜
```
**Key Fixes:**
- âœ… æ›¿æ¢æ¬§æ‹‰è§’ä¸º6Dæ—‹è½¬è¡¨ç¤ºï¼Œé¿å…ä¸‡å‘é”å’Œä¸è¿ç»­æ€§
- âœ… æ·»åŠ tensorç±»å‹æ£€æŸ¥ï¼Œæ”¯æŒnumpy arrayè¾“å…¥
- âœ… æ›´æ–°x_dim=13ä»¥åŒ¹é…æ–°ç‰¹å¾ç»´åº¦

#### **5. Integration with 3DGS Training Loop**:
**è®¾è®¡åŸç†**: æœ€å°åŒ–å¯¹åŸtrain.pyçš„ä¿®æ”¹
- **æ•°æ®æ”¶é›†**: æ¯è½®è®­ç»ƒåæ·»åŠ (camera_features, actual_loss)åˆ°è®­ç»ƒæ•°æ®
- **ç½‘ç»œæ›´æ–°**: æ¯selection_intervalè½®è®­ç»ƒRiskLearner 
- **UIé›†æˆ**: PDTSç½‘ç»œlossæ˜¾ç¤ºåœ¨è¿›åº¦æ¡"PDTS Loss"å­—æ®µ

### Key Components to Borrow from PDTS:
- **RiskLearner Architecture** (Neural Process-based)
- **Posterior Sampling** mechanism  
- **Diversity Regularization** (MSD algorithm)
- **Training Loop** for risk predictor updates

## PDTS Project (Located in PDTS/ folder)
- **Purpose**: Robust active task sampling for adaptive decision-making
- **Core Algorithm**: Combines posterior sampling + diversity regularization
- **Domains**: 
  - sinusoid/ - Regression experiments with MAML
  - RL/DR/ - Reinforcement learning with domain randomization

### Key PDTS Components
1. **RiskLearner**: Neural Process-based risk predictor (uncertainty-aware)
2. **Sampling Strategies**: ERM, DRM, MPTS, PDTS
3. **Diversity Regularization**: Maximum Sum of Distances (MSD)
4. **Acquisition Function**: Î³_Î¼ Ã— Î¼ + Î³_Ïƒ Ã— Ïƒ (exploration vs exploitation)

### PDTS Algorithm Flow
1. Generate candidate tasks
2. Fast difficulty evaluation via risk predictor
3. Select diverse + challenging task subset
4. Train policy on selected tasks
5. Update risk predictor with true performance

## ğŸ”„ INTEGRATION STRATEGY

### Technical Adaptation Challenges:
1. **Input Representation**: 
   - PDTS: Task parameters (amplitude, phase for sinusoid; env params for RL)
   - 3DGS: View parameters (camera pose, intrinsics, etc.)
   - **Solution**: Extract meaningful view features as network input

2. **Output Scaling**:
   - PDTS: Task difficulty scores
   - 3DGS: Rendering loss values
   - **Solution**: Normalize/calibrate loss predictions

3. **Training Data**:
   - PDTS: Meta-learning across different tasks
   - 3DGS: Single scene, multiple views
   - **Solution**: Adapt training loop for single-scene view prediction

### Implementation Plan:
1. **Phase 1**: Create `pdts_integration.py` with basic risk learner
2. **Phase 2**: Extract view features from camera parameters
3. **Phase 3**: Train predictor using current direct loss data
4. **Phase 4**: Replace direct calculation with prediction in `train.py`
5. **Phase 5**: Add diversity regularization and posterior sampling

### Architecture Design:
```
View Features â†’ Risk Learner Network â†’ Predicted Loss â†’ PDTS Sampling â†’ Selected Views
     â†‘                                        â†“
Camera Params                           Ground Truth Loss
(pose, intrinsics)                    (for network training)
```

## Testing and Datasets
- **datasets/** folder contains test data (tandt_db with drjohnson, playroom, train, truck scenes)
- **test_loss_judge.py** - automated testing script comparing baseline vs loss-based selection
- **Test Results**: Stored in test_results/ directory with JSON format

## Important Notes
- PDF paper couldn't be read, but Chinese summary provided good understanding
- Code analysis shows high-quality modular implementation
- PDTS implements multiple baseline methods for comparison
- **CURRENT STATUS**: 32é€‰4 direct loss calculation working, ready for PDTS integration
- **NEXT PRIORITY**: Implement `pdts_integration.py` with bootstrap strategy
- **DESIGN PRINCIPLE**: Keep train.py minimal, put PDTS integration logic in separate file
- **Bootstrap Strategy**: Start with random sampling to collect initial training data, then switch to network prediction
- **Code Strategy**: Copy/reuse PDTS source code for complex mathematical components
- User runs tests on Windows, code modifications done in WSL2

### ğŸ“‹ PDTS Code Mapping (Implementationå®Œæˆåçš„å¯¹ç…§è¡¨):

#### **PDTSæºç  â†’ 3DGSé›†æˆä»£ç æ˜ å°„**:
- `PDTS/sinusoid/Model/backbone_risklearner.py` â†’ `pdts_integration.py` (Encoder, MuSigmaEncoder, Decoder)
- `PDTS/sinusoid/Model/risklearner.py` â†’ `pdts_integration.py` (RiskLearner class)
- `PDTS/sinusoid/Model/trainer_risklearner.py` â†’ `pdts_integration.py` (RiskLearnerTrainer class)
- `PDTS/sinusoid/trainer_maml.py` Line 178-199 â†’ `pdts_integration.py` (msd_diversified_score)
- `PDTS/sinusoid/trainer_maml.py` Line 173,199 â†’ `train.py` Line 240 (training frequency logic)

#### **è¿è¡Œå‘½ä»¤**:
```bash
# PDTSæ¨¡å¼
python train.py -s ./datasets/tandt_db/tandt/truck -m ./output/pdts_test --iterations 1000 --pdts --num_selected_views 4

# å¯¹æ¯”baseline  
python train.py -s ./datasets/tandt_db/tandt/truck -m ./output/baseline_test --iterations 1000
```

## ğŸ“‹ PROJECT SUMMARY  
**What we had**: 3DGS with 32é€‰4 direct loss calculation (slow but working)
**What we implemented**: PDTS neural network integration with dynamic hybrid selection strategy
**Current status**: âœ… å®Œå…¨é‡æ„ä¸ºDynamic Hybrid Strategyï¼Œç†è®ºä¸å·¥ç¨‹å®ç°åŒé‡ä¼˜åŒ–
**Key achievement**: å®ç°Epsilon-Greedyå˜ä½“çš„robustæ··åˆé€‰æ‹©ç­–ç•¥ï¼Œå®Œç¾å¹³è¡¡exploration vs exploitation

### ğŸ”§ **CRITICAL FIXES & MAJOR UPDATES**:

#### **2024-08-07 Update - Strategy Revolution (LATEST)**:
6. **ğŸš€ Dynamic Hybrid Selection Strategy** (REVOLUTIONARY): å®Œå…¨æ¨å€’é‡æ„ï¼Œé‡‡ç”¨åŠ¨æ€æ··åˆç­–ç•¥
   - **New Philosophy**: æ”¾å¼ƒå¤æ‚çŠ¶æ€ç®¡ç†ï¼Œé‡‡ç”¨ç»å…¸çš„Epsilon-Greedyå˜ä½“ç­–ç•¥
   - **Strategy Logic**: 
     - `0-1000è½®`: 100% Random Selection (Bootstrapé˜¶æ®µï¼Œä¸è®­ç»ƒç½‘ç»œï¼Œä¸æ”¶é›†æ•°æ®)
     - `1001+è½®`: 67% Network + 33% Random (Hybridé˜¶æ®µï¼Œå¼€å§‹è®­ç»ƒå’Œæ•°æ®æ”¶é›†)
   - **Key Benefits**:
     - æ— çŠ¶æ€è®¾è®¡ï¼Œæ¶ˆé™¤æ‰€æœ‰opacity resetç›¸å…³å¤æ‚é€»è¾‘
     - æŒç»­æ¢ç´¢ï¼Œæ¯æ‰¹éƒ½å«éšæœºæ€§ï¼Œé˜²æ­¢ç½‘ç»œé”™è¯¯è®¤çŸ¥å¸¦åè®­ç»ƒ
     - æ›´å¼ºé²æ£’æ€§ï¼Œé€‚åº”3DGSè®­ç»ƒä¸­çš„å‰§çƒˆå˜åŒ–
   - **Files Modified**:
     - `pdts_integration.py:335-352` - é‡å†™PDTSViewSelectorç±»æ„é€ å‡½æ•°
     - `pdts_integration.py:358-372` - add_training_data()æ·»åŠ bootstrapè·³è¿‡é€»è¾‘
     - `pdts_integration.py:374-385` - train_network()æ·»åŠ bootstrapè·³è¿‡é€»è¾‘  
     - `pdts_integration.py:380-429` - å®Œå…¨é‡å†™select_views()å®ç°åŠ¨æ€æ··åˆé€‰æ‹©
     - `train.py:85-91` - æ›´æ–°åˆå§‹åŒ–å‚æ•°
   - **Result**: ç­–ç•¥æ›´ç®€æ´ã€é²æ£’ã€æ˜“ç†è§£ï¼Œä»æ ¹æœ¬ä¸Šè§£å†³è®­ç»ƒä¸ç¨³å®šé—®é¢˜

5. **âœ… Time Synchronization Bug** (CRITICAL): ä¿®å¤PDTSå†…éƒ¨è®¡æ•°å™¨ä¸ä¸»è®­ç»ƒå¾ªç¯ä¸åŒæ­¥é—®é¢˜
   - **Problem**: PDTSå†…éƒ¨ç»´æŠ¤`self.iteration`è®¡æ•°å™¨ï¼Œä¸`train.py`ä¸»å¾ªç¯çš„`iteration`å˜é‡è„±èŠ‚
   - **Solution**: å®Œå…¨ç§»é™¤å†…éƒ¨`self.iteration`ï¼Œæ”¹ä¸ºæ— çŠ¶æ€è®¾è®¡
   - **Result**: PDTSæ—¶é—´åˆ¤æ–­ä¸ä¸»è®­ç»ƒå¾ªç¯å®Œå…¨åŒæ­¥

#### **Previous Fixes** (Foundation):
1. **Diversity Scoring Algorithm**: Min-Maxå½’ä¸€åŒ–ï¼Œç¡®ä¿acquisitionå’Œdiversity scoreåœ¨ç›¸åŒå°ºåº¦
2. **Posterior Sampling Mechanism**: çœŸæ­£çš„stochastic sampleï¼Œç¬¦åˆThompson Samplingç†è®º
3. **Camera Feature Representation**: 6Dæ—‹è½¬è¡¨ç¤ºï¼Œé¿å…ä¸‡å‘é”ï¼Œx_dim=13ç»´
4. **Code Robustness**: æ”¯æŒæ··åˆæ•°æ®ç±»å‹ï¼Œé˜²æ­¢è¿è¡Œæ—¶é”™è¯¯

### ğŸ¯ **CURRENT ARCHITECTURE** (Dynamic Hybrid Strategy):

```
Training Flow:
â”œâ”€â”€ 0-1000è½® (Bootstrap Phase)
â”‚   â”œâ”€â”€ View Selection: 100% Random
â”‚   â”œâ”€â”€ Data Collection: âŒ Skipped
â”‚   â””â”€â”€ Network Training: âŒ Skipped
â”‚
â””â”€â”€ 1001+è½® (Hybrid Phase)  
    â”œâ”€â”€ View Selection: 67% Network + 33% Random
    â”œâ”€â”€ Data Collection: âœ… Active
    â””â”€â”€ Network Training: âœ… Active
```

**Selection Logic**:
- **num_selected=4æ—¶**: `round(4 Ã— 2/3) = 3`ç½‘ç»œé€‰æ‹© + `1`éšæœºé€‰æ‹©
- **æ— é‡å ä¿è¯**: éšæœºé€‰æ‹©ä»éç½‘ç»œé€‰æ‹©çš„è§†å›¾ä¸­é‡‡æ ·
- **åŠ¨æ€åˆ‡æ¢**: åŸºäº`current_iteration`è‡ªåŠ¨åˆ¤æ–­ä½¿ç”¨å“ªç§ç­–ç•¥

### ğŸ† **CURRENT STATUS**:
- **Core Strategy**: âœ… Dynamic Hybrid Strategyå®Œå…¨å®ç°ï¼Œç»å…¸Epsilon-Greedyå˜ä½“
- **Architecture**: âœ… æ— çŠ¶æ€ã€æ— å¤æ‚æ—¶é—´é€»è¾‘ã€é«˜åº¦é²æ£’
- **Integration**: âœ… ä¸3DGSè®­ç»ƒå¾ªç¯å®Œç¾é›†æˆï¼Œå‚æ•°ä¼ é€’æ­£ç¡®
- **Bootstrap Logic**: âœ… å‰1000è½®çº¯ç²¹éšæœºï¼Œä¸å¹²æ‰°3DGSè‡ªèº«è®­ç»ƒ
- **Hybrid Logic**: âœ… 1000è½®åå¼€å§‹æ™ºèƒ½é€‰æ‹©ï¼ŒæŒç»­explorationä¿è¯
- **Ready for**: å®é™…è®­ç»ƒæµ‹è¯•ï¼ŒéªŒè¯æ–°ç­–ç•¥çš„ç¨³å®šæ€§å’Œæ€§èƒ½æå‡

**Expected Benefits**: è®­ç»ƒæ›´ç¨³å®šï¼ŒPSNRæ›²çº¿æ›´å¹³æ»‘ï¼Œå¯¹opacity resetç­‰çªå˜æ›´åŠ é€‚åº”